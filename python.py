# project_evaluation_app.py

import streamlit as st
import pandas as pd
import numpy as np
import google.generativeai as genai
from google.api_core.exceptions import GoogleAPIError
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from docx import Document
import io
import json

# --- C·∫•u h√¨nh Trang Streamlit ---
st.set_page_config(
    page_title="App ƒê√°nh Gi√° Ph∆∞∆°ng √Ån Kinh Doanh",
    layout="wide"
)

st.title("·ª®ng d·ª•ng ƒê√°nh Gi√° Ph∆∞∆°ng √Ån Kinh Doanh üìà")

# --- Kh·ªüi t·∫°o Session State ---
if "extracted_data" not in st.session_state:
    st.session_state.extracted_data = None
if "cash_flow_df" not in st.session_state:
    st.session_state.cash_flow_df = None
if "metrics" not in st.session_state:
    st.session_state.metrics = {}
if "ai_analysis" not in st.session_state:
    st.session_state.ai_analysis = None

# --- H√†m ƒë·ªçc file Word ---
@st.cache_data
def read_word_file(uploaded_file):
    """ƒê·ªçc n·ªôi dung t·ª´ file Word."""
    doc = Document(uploaded_file)
    full_text = []
    for paragraph in doc.paragraphs:
        full_text.append(paragraph.text)
    return '\n'.join(full_text)

# --- H√†m g·ªçi API Gemini ƒë·ªÉ Extract D·ªØ li·ªáu ---
def extract_project_data(full_text, api_key):
    """S·ª≠ d·ª•ng Gemini ƒë·ªÉ extract th√¥ng tin d·ª± √°n t·ª´ text."""
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(
            model_name='gemini-2.5-flash',
            generation_config=genai.types.GenerationConfig(
                temperature=0.1,
                top_p=0.8,
                max_output_tokens=2048,  # TƒÉng ƒë·ªÉ tr√°nh MAX_TOKENS
            ),
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }
        )

        prompt = f"""
        B·∫°n l√† chuy√™n gia ph√¢n t√≠ch d·ª± √°n kinh doanh. T·ª´ vƒÉn b·∫£n m√¥ t·∫£ ph∆∞∆°ng √°n kinh doanh sau, h√£y extract c√°c th√¥ng tin sau d∆∞·ªõi d·∫°ng JSON h·ª£p l·ªá, ng·∫Øn g·ªçn nh·∫•t c√≥ th·ªÉ:
        - "von_dau_tu": V·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu (s·ªë, ƒë∆°n v·ªã VND ho·∫∑c USD, n·∫øu kh√¥ng c√≥ gi·∫£ s·ª≠ 0).
        - "dong_doi_du_an": D√≤ng ƒë·ªùi d·ª± √°n (s·ªë nƒÉm, n·∫øu kh√¥ng c√≥ gi·∫£ s·ª≠ 5).
        - "doanh_thu": Danh s√°ch doanh thu theo nƒÉm [nƒÉm1, nƒÉm2, ..., nƒÉmN] (danh s√°ch s·ªë, n·∫øu constant th√¨ l·∫∑p l·∫°i).
        - "chi_phi": Danh s√°ch chi ph√≠ theo nƒÉm [nƒÉm1, nƒÉm2, ..., nƒÉmN] (danh s√°ch s·ªë, t∆∞∆°ng ·ª©ng doanh thu).
        - "wacc": WACC (t·ª∑ l·ªá %, d·∫°ng s·ªë th·∫≠p ph√¢n nh∆∞ 0.08 cho 8%).
        - "thue": T·ª∑ l·ªá thu·∫ø (%, d·∫°ng s·ªë th·∫≠p ph√¢n nh∆∞ 0.20 cho 20%).

        N·∫øu th√¥ng tin kh√¥ng ƒë·∫ßy ƒë·ªß, s·ª≠ d·ª•ng gi√° tr·ªã m·∫∑c ƒë·ªãnh h·ª£p l√Ω (v√≠ d·ª•: doanh thu/chi ph√≠ tƒÉng 5%/nƒÉm n·∫øu ch·ªâ c√≥ nƒÉm ƒë·∫ßu).
        ƒê·∫£m b·∫£o danh s√°ch doanh thu v√† chi ph√≠ c√≥ ƒë·ªô d√†i b·∫±ng dong_doi_du_an. Gi·ªØ JSON ng·∫Øn g·ªçn.

        VƒÉn b·∫£n:
        {full_text[:3000]}  # Gi·∫£m ƒë·ªÉ tr√°nh token input cao
        """

        response = model.generate_content(prompt)
        
        # X·ª≠ l√Ω response an to√†n
        if not response.candidates or len(response.candidates) == 0:
            return {"error": "Kh√¥ng c√≥ candidates trong response."}
        
        candidate = response.candidates[0]
        
        # Ki·ªÉm tra safety
        if candidate.safety_ratings:
            for rating in candidate.safety_ratings:
                if rating.probability.name == "BLOCKED":
                    return {"error": f"Response b·ªã block b·ªüi safety: {rating.category.name}"}
        
        # Ki·ªÉm tra finish_reason
        if candidate.finish_reason.name != "STOP":
            return {"error": f"Generation kh√¥ng ho√†n t·∫•t. Finish reason: {candidate.finish_reason.name}"}
        
        # L·∫•y text t·ª´ parts
        if candidate.content and candidate.content.parts:
            text = candidate.content.parts[0].text
        else:
            return {"error": "Kh√¥ng c√≥ content parts trong response."}
        
        # Parse JSON
        try:
            data = json.loads(text.strip())
            return data
        except json.JSONDecodeError as e:
            return {"error": f"Kh√¥ng th·ªÉ parse JSON t·ª´ AI response: {e}. Raw text: {text[:200]}"}

    except GoogleAPIError as e:
        return {"error": f"L·ªói g·ªçi Gemini API: {e}"}
    except Exception as e:
        return {"error": f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"}

# --- H√†m x√¢y d·ª±ng b·∫£ng d√≤ng ti·ªÅn ---
@st.cache_data
def build_cash_flow(extracted_data):
    """X√¢y d·ª±ng b·∫£ng d√≤ng ti·ªÅn t·ª´ d·ªØ li·ªáu extract."""
    if "error" in extracted_data:
        return None, None

    investment = extracted_data.get("von_dau_tu", 0)
    years = extracted_data.get("dong_doi_du_an", 5)
    revenues = extracted_data.get("doanh_thu", [0] * years)
    costs = extracted_data.get("chi_phi", [0] * years)
    tax_rate = extracted_data.get("thue", 0.2)
    wacc = extracted_data.get("wacc", 0.1)

    # ƒê·∫£m b·∫£o lists c√≥ ƒë√∫ng length v√† l√† s·ªë
    if isinstance(revenues, list) and len(revenues) != years:
        if revenues:
            rev0 = float(revenues[0]) if revenues[0] else 1000000000
            revenues = [rev0 * (1.05 ** i) for i in range(years)]  # Gi·∫£ s·ª≠ tƒÉng 5%
        else:
            revenues = [1000000000] * years
    elif not isinstance(revenues, list):
        revenues = [float(revenues)] * years if revenues else [1000000000] * years

    if isinstance(costs, list) and len(costs) != years:
        if costs:
            cost0 = float(costs[0]) if costs[0] else 800000000
            costs = [cost0 * (1.03 ** i) for i in range(years)]  # Gi·∫£ s·ª≠ tƒÉng 3%
        else:
            costs = [800000000] * years
    elif not isinstance(costs, list):
        costs = [float(costs)] * years if costs else [800000000] * years

    cash_flows = [-float(investment)]
    for i in range(years):
        ebit = revenues[i] - costs[i]
        tax = ebit * tax_rate if ebit > 0 else 0
        net_cf = ebit - tax
        cash_flows.append(net_cf)

    df = pd.DataFrame({
        'NƒÉm': list(range(0, years + 1)),
        'D√≤ng ti·ªÅn (VND)': cash_flows
    })
    return df, float(wacc)

# --- H√†m t√≠nh IRR kh√¥ng d√πng scipy ---
def calculate_irr(cash_flows, tol=1e-6, max_iter=100):
    """T√≠nh IRR b·∫±ng ph∆∞∆°ng ph√°p bisection."""
    if len(cash_flows) < 2:
        return np.nan
    
    low = -0.99
    high = 10.0  # TƒÉng high ƒë·ªÉ handle IRR cao
    
    for _ in range(max_iter):
        mid = (low + high) / 2
        npv_mid = np.npv(mid, cash_flows)
        if abs(npv_mid) < tol:
            return mid
        if npv_mid > 0:
            low = mid
        else:
            high = mid
    
    return mid  # approximate

# --- H√†m t√≠nh to√°n ch·ªâ s·ªë hi·ªáu qu·∫£ ---
@st.cache_data
def calculate_metrics(cash_flows, wacc):
    """T√≠nh NPV, IRR, PP, DPP."""
    if len(cash_flows) < 2:
        return {}

    # NPV
    npv = np.npv(wacc, cash_flows)

    # IRR
    irr = calculate_irr(cash_flows)

    # PP (Payback Period) - interpolate for precision
    cumulative_cf = np.cumsum(cash_flows)
    if cumulative_cf[-1] < 0:
        pp = np.inf
    else:
        pp_idx = np.argmax(cumulative_cf >= 0)
        if pp_idx == 0:
            pp = 0
        elif pp_idx == len(cash_flows):
            pp = len(cash_flows) - 1
        else:
            prev_cum = cumulative_cf[pp_idx - 1]
            period_cf = cash_flows[pp_idx]
            pp = (pp_idx - 1) + (-prev_cum / period_cf)

    # DPP (Discounted Payback)
    discounted_cf = [cf / (1 + wacc)**t for t, cf in enumerate(cash_flows)]
    cumulative_disc = np.cumsum(discounted_cf)
    if cumulative_disc[-1] < 0:
        dpp = np.inf
    else:
        dpp_idx = np.argmax(cumulative_disc >= 0)
        if dpp_idx == 0:
            dpp = 0
        elif dpp_idx == len(discounted_cf):
            dpp = len(discounted_cf) - 1
        else:
            prev_cum_disc = cumulative_disc[dpp_idx - 1]
            period_disc_cf = discounted_cf[dpp_idx]
            dpp = (dpp_idx - 1) + (-prev_cum_disc / period_disc_cf)

    return {
        'NPV': npv,
        'IRR': irr * 100 if not np.isnan(irr) else np.nan,
        'PP': round(pp, 2) if not np.isinf(pp) else "Ch∆∞a ho√†n v·ªën",
        'DPP': round(dpp, 2) if not np.isinf(dpp) else "Ch∆∞a ho√†n v·ªën",
        'WACC': wacc * 100
    }

# --- H√†m g·ªçi AI ph√¢n t√≠ch ch·ªâ s·ªë ---
def get_ai_metrics_analysis(metrics, api_key):
    """G·ª≠i metrics ƒë·∫øn Gemini ƒë·ªÉ ph√¢n t√≠ch."""
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(
            model_name='gemini-2.5-flash',
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                top_p=0.8,
                max_output_tokens=1024,  # TƒÉng m·ªôt ch√∫t
            ),
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }
        )

        prompt = f"""
        B·∫°n l√† chuy√™n gia ƒë√°nh gi√° d·ª± √°n kinh doanh. D·ª±a tr√™n c√°c ch·ªâ s·ªë sau, h√£y ph√¢n t√≠ch hi·ªáu qu·∫£ d·ª± √°n m·ªôt c√°ch kh√°ch quan (3-4 ƒëo·∫°n ng·∫Øn g·ªçn):
        - NPV > 0: H·∫•p d·∫´n.
        - IRR > WACC: T·ªët.
        - PP < 3 nƒÉm: Nhanh.
        - DPP < 4 nƒÉm: H·ª£p l√Ω.

        Ch·ªâ s·ªë:
        NPV: {metrics.get('NPV', 0):,.0f} VND
        IRR: {metrics.get('IRR', 0):.2f}%
        PP: {metrics.get('PP', 0)} nƒÉm
        DPP: {metrics.get('DPP', 0)} nƒÉm
        WACC: {metrics.get('WACC', 0):.2f}%
        """

        response = model.generate_content(prompt)
        
        # X·ª≠ l√Ω response an to√†n t∆∞∆°ng t·ª±
        if not response.candidates or len(response.candidates) == 0:
            return "Kh√¥ng c√≥ candidates trong response."
        
        candidate = response.candidates[0]
        
        if candidate.safety_ratings:
            for rating in candidate.safety_ratings:
                if rating.probability.name == "BLOCKED":
                    return f"Response b·ªã block b·ªüi safety: {rating.category.name}"
        
        if candidate.finish_reason.name != "STOP":
            return f"Generation kh√¥ng ho√†n t·∫•t. Finish reason: {candidate.finish_reason.name}"
        
        if candidate.content and candidate.content.parts:
            text = candidate.content.parts[0].text
        else:
            return "Kh√¥ng c√≥ content parts trong response."
        
        return text

    except GoogleAPIError as e:
        return f"L·ªói g·ªçi Gemini API: {e}"
    except Exception as e:
        return f"L·ªói: {e}"

# --- UI: Ch·ª©c nƒÉng 1 - T·∫£i v√† L·ªçc D·ªØ li·ªáu ---
st.header("1. T·∫£i File Word v√† L·ªçc D·ªØ li·ªáu D·ª± √°n")

uploaded_file = st.file_uploader("Ch·ªçn file Word (.docx)", type=['docx'])

if uploaded_file is not None:
    full_text = read_word_file(uploaded_file)
    st.text_area("N·ªôi dung file (preview):", full_text[:1000], height=200)

    if st.button("üîç L·ªçc D·ªØ li·ªáu b·∫±ng AI"):
        api_key = st.secrets.get("GEMINI_API_KEY")
        if not api_key:
            st.error("L·ªói: C·∫•u h√¨nh GEMINI_API_KEY trong Streamlit Secrets.")
        else:
            with st.spinner("ƒêang extract d·ªØ li·ªáu..."):
                extracted = extract_project_data(full_text, api_key)
                if "error" in extracted:
                    st.error(extracted["error"])
                else:
                    st.session_state.extracted_data = extracted
                    st.success("Extract th√†nh c√¥ng!")
                    st.json(extracted)

# --- Ch·ª©c nƒÉng 2: X√¢y d·ª±ng B·∫£ng D√≤ng Ti·ªÅn ---
if st.session_state.extracted_data and "error" not in st.session_state.extracted_data:
    st.header("2. B·∫£ng D√≤ng Ti·ªÅn D·ª± √Ån")
    if st.button("üìä X√¢y d·ª±ng B·∫£ng D√≤ng Ti·ªÅn"):
        cash_flow_df, wacc = build_cash_flow(st.session_state.extracted_data)
        if cash_flow_df is not None:
            st.session_state.cash_flow_df = cash_flow_df
            st.session_state.wacc = wacc
            st.dataframe(cash_flow_df.style.format({'D√≤ng ti·ªÅn (VND)': '{:,.0f}'}), use_container_width=True)

# --- Ch·ª©c nƒÉng 3: T√≠nh To√°n Ch·ªâ S·ªë ---
if st.session_state.cash_flow_df is not None:
    st.header("3. C√°c Ch·ªâ S·ªë ƒê√°nh Gi√° Hi·ªáu Qu·∫£")
    cash_flows = st.session_state.cash_flow_df['D√≤ng ti·ªÅn (VND)'].tolist()
    wacc_rate = st.session_state.wacc

    metrics = calculate_metrics(cash_flows, wacc_rate)
    st.session_state.metrics = metrics

    col1, col2 = st.columns(2)
    with col1:
        st.metric("NPV", f"{metrics['NPV']:,.0f} VND")
        irr_val = f"{metrics['IRR']:.2f}%" if not np.isnan(metrics['IRR']) else "N/A"
        st.metric("IRR", irr_val)
    with col2:
        st.metric("PP", f"{metrics['PP']}" if isinstance(metrics['PP'], str) else f"{metrics['PP']} nƒÉm")
        st.metric("DPP", f"{metrics['DPP']}" if isinstance(metrics['DPP'], str) else f"{metrics['DPP']} nƒÉm")

# --- Ch·ª©c nƒÉng 4: Ph√¢n T√≠ch AI ---
if st.session_state.metrics:
    st.header("4. Ph√¢n T√≠ch Ch·ªâ S·ªë b·ªüi AI")
    if st.button("ü§ñ Y√™u C·∫ßu AI Ph√¢n T√≠ch"):
        api_key = st.secrets.get("GEMINI_API_KEY")
        if api_key:
            with st.spinner("ƒêang ph√¢n t√≠ch..."):
                analysis = get_ai_metrics_analysis(st.session_state.metrics, api_key)
                st.session_state.ai_analysis = analysis
                st.markdown("**Ph√¢n t√≠ch t·ª´ AI:**")
                if "error" in analysis.lower() or "l·ªói" in analysis.lower():
                    st.error(analysis)
                else:
                    st.info(analysis)
        else:
            st.error("L·ªói: C·∫•u h√¨nh GEMINI_API_KEY.")

# --- Export ---
if st.session_state.cash_flow_df is not None:
    col_export1, col_export2 = st.columns(2)
    with col_export1:
        if st.button("üì• T·∫£i B·∫£ng D√≤ng Ti·ªÅn Excel"):
            output = io.BytesIO()
            st.session_state.cash_flow_df.to_excel(output, index=False)
            output.seek(0)
            st.download_button(
                label="T·∫£i file",
                data=output.getvalue(),
                file_name="bang_dong_tien.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    with col_export2:
        if st.button("üì• T·∫£i Metrics Excel"):
            # Format metrics for export
            export_metrics = {k: v if not isinstance(v, str) else v for k, v in st.session_state.metrics.items()}
            metrics_df = pd.DataFrame(list(export_metrics.items()), columns=['Ch·ªâ s·ªë', 'Gi√° tr·ªã'])
            output = io.BytesIO()
            metrics_df.to_excel(output, index=False)
            output.seek(0)
            st.download_button(
                label="T·∫£i file",
                data=output.getvalue(),
                file_name="chi_so_metrics.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
else:
    st.info("Vui l√≤ng t·∫£i file Word v√† th·ª±c hi·ªán c√°c b∆∞·ªõc ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
