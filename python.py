# project_evaluation_app.py

import streamlit as st
import pandas as pd
import numpy as np
from scipy.optimize import newton
import google.generativeai as genai
from google.api_core.exceptions import GoogleAPIError
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from docx import Document
import io

# --- C·∫•u h√¨nh Trang Streamlit ---
st.set_page_config(
    page_title="App ƒê√°nh Gi√° Ph∆∞∆°ng √Ån Kinh Doanh",
    layout="wide"
)

st.title("·ª®ng d·ª•ng ƒê√°nh Gi√° Ph∆∞∆°ng √Ån Kinh Doanh üìà")

# --- Kh·ªüi t·∫°o Session State ---
if "extracted_data" not in st.session_state:
    st.session_state.extracted_data = None
if "cash_flow_df" not in st.session_state:
    st.session_state.cash_flow_df = None
if "metrics" not in st.session_state:
    st.session_state.metrics = {}
if "ai_analysis" not in st.session_state:
    st.session_state.ai_analysis = None

# --- H√†m ƒë·ªçc file Word ---
@st.cache_data
def read_word_file(uploaded_file):
    """ƒê·ªçc n·ªôi dung t·ª´ file Word."""
    doc = Document(uploaded_file)
    full_text = []
    for paragraph in doc.paragraphs:
        full_text.append(paragraph.text)
    return '\n'.join(full_text)

# --- H√†m g·ªçi API Gemini ƒë·ªÉ Extract D·ªØ li·ªáu ---
def extract_project_data(full_text, api_key):
    """S·ª≠ d·ª•ng Gemini ƒë·ªÉ extract th√¥ng tin d·ª± √°n t·ª´ text."""
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(
            model_name='gemini-1.5-flash',
            generation_config=genai.types.GenerationConfig(
                temperature=0.1,  # Th·∫•p ƒë·ªÉ extract ch√≠nh x√°c
                top_p=0.8,
                max_output_tokens=500,
            ),
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }
        )

        prompt = f"""
        B·∫°n l√† chuy√™n gia ph√¢n t√≠ch d·ª± √°n kinh doanh. T·ª´ vƒÉn b·∫£n m√¥ t·∫£ ph∆∞∆°ng √°n kinh doanh sau, h√£y extract c√°c th√¥ng tin sau d∆∞·ªõi d·∫°ng JSON h·ª£p l·ªá:
        - "von_dau_tu": V·ªën ƒë·∫ßu t∆∞ ban ƒë·∫ßu (s·ªë, ƒë∆°n v·ªã VND ho·∫∑c USD, n·∫øu kh√¥ng c√≥ gi·∫£ s·ª≠ 0).
        - "dong_doi_du_an": D√≤ng ƒë·ªùi d·ª± √°n (s·ªë nƒÉm, n·∫øu kh√¥ng c√≥ gi·∫£ s·ª≠ 5).
        - "doanh_thu": Danh s√°ch doanh thu theo nƒÉm [nƒÉm1, nƒÉm2, ..., nƒÉmN] (danh s√°ch s·ªë, n·∫øu constant th√¨ l·∫∑p l·∫°i).
        - "chi_phi": Danh s√°ch chi ph√≠ theo nƒÉm [nƒÉm1, nƒÉm2, ..., nƒÉmN] (danh s√°ch s·ªë, t∆∞∆°ng ·ª©ng doanh thu).
        - "wacc": WACC (t·ª∑ l·ªá %, d·∫°ng s·ªë th·∫≠p ph√¢n nh∆∞ 0.08 cho 8%).
        - "thue": T·ª∑ l·ªá thu·∫ø (%, d·∫°ng s·ªë th·∫≠p ph√¢n nh∆∞ 0.20 cho 20%).

        N·∫øu th√¥ng tin kh√¥ng ƒë·∫ßy ƒë·ªß, s·ª≠ d·ª•ng gi√° tr·ªã m·∫∑c ƒë·ªãnh h·ª£p l√Ω (v√≠ d·ª•: doanh thu/chi ph√≠ tƒÉng 5%/nƒÉm n·∫øu ch·ªâ c√≥ nƒÉm ƒë·∫ßu).
        ƒê·∫£m b·∫£o danh s√°ch doanh thu v√† chi ph√≠ c√≥ ƒë·ªô d√†i b·∫±ng dong_doi_du_an.

        VƒÉn b·∫£n:
        {full_text[:4000]}  # Gi·ªõi h·∫°n ƒë·ªÉ tr√°nh token limit
        """

        response = model.generate_content(prompt)
        # Gi·∫£ s·ª≠ response.text l√† JSON string, parse n√≥
        import json
        try:
            data = json.loads(response.text.strip())
            return data
        except json.JSONDecodeError:
            return {"error": "Kh√¥ng th·ªÉ parse JSON t·ª´ AI response."}

    except GoogleAPIError as e:
        return {"error": f"L·ªói g·ªçi Gemini API: {e}"}
    except Exception as e:
        return {"error": f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"}

# --- H√†m x√¢y d·ª±ng b·∫£ng d√≤ng ti·ªÅn ---
@st.cache_data
def build_cash_flow(extracted_data):
    """X√¢y d·ª±ng b·∫£ng d√≤ng ti·ªÅn t·ª´ d·ªØ li·ªáu extract."""
    if "error" in extracted_data:
        return None

    investment = extracted_data.get("von_dau_tu", 0)
    years = extracted_data.get("dong_doi_du_an", 5)
    revenues = extracted_data.get("doanh_thu", [0] * years)
    costs = extracted_data.get("chi_phi", [0] * years)
    tax_rate = extracted_data.get("thue", 0.2)
    wacc = extracted_data.get("wacc", 0.1)

    # ƒê·∫£m b·∫£o lists c√≥ ƒë√∫ng length
    if len(revenues) != years:
        revenues = [revenues[0]] * years if revenues else [1000000000] * years  # Default
    if len(costs) != years:
        costs = [costs[0]] * years if costs else [800000000] * years  # Default

    cash_flows = [-investment]
    for i in range(years):
        ebit = revenues[i] - costs[i]
        tax = ebit * tax_rate if ebit > 0 else 0
        net_cf = ebit - tax  # Gi·∫£n l∆∞·ª£c, gi·∫£ s·ª≠ no depreciation etc.
        cash_flows.append(net_cf)

    df = pd.DataFrame({
        'NƒÉm': list(range(0, years + 1)),
        'D√≤ng ti·ªÅn (VND)': cash_flows
    })
    return df, wacc

# --- H√†m t√≠nh to√°n ch·ªâ s·ªë hi·ªáu qu·∫£ ---
@st.cache_data
def calculate_metrics(cash_flows, wacc):
    """T√≠nh NPV, IRR, PP, DPP."""
    if len(cash_flows) < 2:
        return {}

    # NPV
    npv = np.npv(wacc, cash_flows)

    # IRR
    def irr_func(rate):
        return np.npv(rate, cash_flows)
    try:
        irr = newton(irr_func, 0.1)  # Initial guess 10%
    except:
        irr = np.nan

    # PP (Payback Period)
    cumulative_cf = np.cumsum(cash_flows)
    pp = np.argmax(cumulative_cf >= 0)
    if cumulative_cf[pp] < 0:
        pp = len(cash_flows)  # Not recovered

    # DPP (Discounted Payback)
    discounted_cf = [cf / (1 + wacc)**t for t, cf in enumerate(cash_flows)]
    cumulative_disc = np.cumsum(discounted_cf)
    dpp = np.argmax(cumulative_disc >= 0)
    if cumulative_disc[dpp] < 0:
        dpp = len(cash_flows)

    return {
        'NPV': npv,
        'IRR': irr * 100 if not np.isnan(irr) else np.nan,  # %
        'PP': pp,
        'DPP': dpp,
        'WACC': wacc * 100  # %
    }

# --- H√†m g·ªçi AI ph√¢n t√≠ch ch·ªâ s·ªë ---
def get_ai_metrics_analysis(metrics, api_key):
    """G·ª≠i metrics ƒë·∫øn Gemini ƒë·ªÉ ph√¢n t√≠ch."""
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(
            model_name='gemini-1.5-flash',
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                top_p=0.8,
                max_output_tokens=800,
            ),
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }
        )

        prompt = f"""
        B·∫°n l√† chuy√™n gia ƒë√°nh gi√° d·ª± √°n kinh doanh. D·ª±a tr√™n c√°c ch·ªâ s·ªë sau, h√£y ph√¢n t√≠ch hi·ªáu qu·∫£ d·ª± √°n m·ªôt c√°ch kh√°ch quan (3-4 ƒëo·∫°n):
        - NPV > 0: H·∫•p d·∫´n.
        - IRR > WACC: T·ªët.
        - PP < 3 nƒÉm: Nhanh.
        - DPP < 4 nƒÉm: H·ª£p l√Ω.

        Ch·ªâ s·ªë:
        NPV: {metrics.get('NPV', 0):,.0f} VND
        IRR: {metrics.get('IRR', 0):.2f}%
        PP: {metrics.get('PP', 0)} nƒÉm
        DPP: {metrics.get('DPP', 0)} nƒÉm
        WACC: {metrics.get('WACC', 0):.2f}%
        """

        response = model.generate_content(prompt)
        return response.text

    except GoogleAPIError as e:
        return f"L·ªói g·ªçi Gemini API: {e}"
    except Exception as e:
        return f"L·ªói: {e}"

# --- UI: Ch·ª©c nƒÉng 1 - T·∫£i v√† L·ªçc D·ªØ li·ªáu ---
st.header("1. T·∫£i File Word v√† L·ªçc D·ªØ li·ªáu D·ª± √°n")

uploaded_file = st.file_uploader("Ch·ªçn file Word (.docx)", type=['docx'])

if uploaded_file is not None:
    full_text = read_word_file(uploaded_file)
    st.text_area("N·ªôi dung file (preview):", full_text[:1000], height=200)

    if st.button("üîç L·ªçc D·ªØ li·ªáu b·∫±ng AI"):
        api_key = st.secrets.get("GEMINI_API_KEY")
        if not api_key:
            st.error("L·ªói: C·∫•u h√¨nh GEMINI_API_KEY trong Streamlit Secrets.")
        else:
            with st.spinner("ƒêang extract d·ªØ li·ªáu..."):
                extracted = extract_project_data(full_text, api_key)
                if "error" in extracted:
                    st.error(extracted["error"])
                else:
                    st.session_state.extracted_data = extracted
                    st.success("Extract th√†nh c√¥ng!")
                    st.json(extracted)

# --- Ch·ª©c nƒÉng 2: X√¢y d·ª±ng B·∫£ng D√≤ng Ti·ªÅn ---
if st.session_state.extracted_data:
    st.header("2. B·∫£ng D√≤ng Ti·ªÅn D·ª± √Ån")
    if st.button("üìä X√¢y d·ª±ng B·∫£ng D√≤ng Ti·ªÅn"):
        cash_flow_df, wacc = build_cash_flow(st.session_state.extracted_data)
        if cash_flow_df is not None:
            st.session_state.cash_flow_df = cash_flow_df
            st.session_state.wacc = wacc
            st.dataframe(cash_flow_df.style.format({'D√≤ng ti·ªÅn (VND)': '{:,.0f}'}), use_container_width=True)

# --- Ch·ª©c nƒÉng 3: T√≠nh To√°n Ch·ªâ S·ªë ---
if st.session_state.cash_flow_df is not None:
    st.header("3. C√°c Ch·ªâ S·ªë ƒê√°nh Gi√° Hi·ªáu Qu·∫£")
    cash_flows = st.session_state.cash_flow_df['D√≤ng ti·ªÅn (VND)'].tolist()
    wacc_rate = st.session_state.wacc

    metrics = calculate_metrics(cash_flows, wacc_rate)
    st.session_state.metrics = metrics

    col1, col2 = st.columns(2)
    with col1:
        st.metric("NPV", f"{metrics['NPV']:,.0f} VND")
        st.metric("IRR", f"{metrics['IRR']:.2f}%")
    with col2:
        st.metric("PP", f"{metrics['PP']} nƒÉm")
        st.metric("DPP", f"{metrics['DPP']} nƒÉm")

# --- Ch·ª©c nƒÉng 4: Ph√¢n T√≠ch AI ---
if st.session_state.metrics:
    st.header("4. Ph√¢n T√≠ch Ch·ªâ S·ªë b·ªüi AI")
    if st.button("ü§ñ Y√™u C·∫ßu AI Ph√¢n T√≠ch"):
        api_key = st.secrets.get("GEMINI_API_KEY")
        if api_key:
            with st.spinner("ƒêang ph√¢n t√≠ch..."):
                analysis = get_ai_metrics_analysis(st.session_state.metrics, api_key)
                st.session_state.ai_analysis = analysis
                st.markdown("**Ph√¢n t√≠ch t·ª´ AI:**")
                st.info(analysis)
        else:
            st.error("L·ªói: C·∫•u h√¨nh GEMINI_API_KEY.")

# --- Export ---
if st.session_state.cash_flow_df is not None:
    col_export1, col_export2 = st.columns(2)
    with col_export1:
        if st.button("üì• T·∫£i B·∫£ng D√≤ng Ti·ªÅn Excel"):
            output = io.BytesIO()
            st.session_state.cash_flow_df.to_excel(output, index=False)
            output.seek(0)
            st.download_button(
                label="T·∫£i file",
                data=output.getvalue(),
                file_name="bang_dong_tien.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    with col_export2:
        if st.button("üì• T·∫£i Metrics Excel"):
            metrics_df = pd.DataFrame(list(st.session_state.metrics.items()), columns=['Ch·ªâ s·ªë', 'Gi√° tr·ªã'])
            output = io.BytesIO()
            metrics_df.to_excel(output, index=False)
            output.seek(0)
            st.download_button(
                label="T·∫£i file",
                data=output.getvalue(),
                file_name="chi_so_metrics.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
else:
    st.info("Vui l√≤ng t·∫£i file Word v√† th·ª±c hi·ªán c√°c b∆∞·ªõc ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
