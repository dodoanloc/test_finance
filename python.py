# python.py

import streamlit as st
import pandas as pd
import google.generativeai as genai
from google.api_core.exceptions import GoogleAPIError
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import io  # ƒê·ªÉ export file

# --- C·∫•u h√¨nh Trang Streamlit ---
st.set_page_config(
    page_title="App Ph√¢n T√≠ch B√°o C√°o T√†i Ch√≠nh",
    layout="wide"
)

st.title("·ª®ng d·ª•ng Ph√¢n T√≠ch B√°o C√°o T√†i Ch√≠nh üìä")

# --- Kh·ªüi t·∫°o Session State cho Chat ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "df_processed" not in st.session_state:
    st.session_state.df_processed = None
if "data_for_ai" not in st.session_state:
    st.session_state.data_for_ai = None
if "thanh_toan_hien_hanh_N_1" not in st.session_state:
    st.session_state.thanh_toan_hien_hanh_N_1 = "N/A"
if "thanh_toan_hien_hanh_N" not in st.session_state:
    st.session_state.thanh_toan_hien_hanh_N = "N/A"

# --- H√†m t√≠nh to√°n ch√≠nh (S·ª≠ d·ª•ng Caching ƒë·ªÉ T·ªëi ∆∞u hi·ªáu su·∫•t) ---
@st.cache_data
def process_financial_data(df):
    """Th·ª±c hi·ªán c√°c ph√©p t√≠nh TƒÉng tr∆∞·ªüng v√† T·ª∑ tr·ªçng."""
    
    # ƒê·∫£m b·∫£o c√°c gi√° tr·ªã l√† s·ªë ƒë·ªÉ t√≠nh to√°n
    numeric_cols = ['NƒÉm tr∆∞·ªõc', 'NƒÉm sau']
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    
    # 1. T√≠nh T·ªëc ƒë·ªô TƒÉng tr∆∞·ªüng
    df['T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)'] = (
        (df['NƒÉm sau'] - df['NƒÉm tr∆∞·ªõc']) / df['NƒÉm tr∆∞·ªõc'].replace(0, 1e-9)
    ) * 100

    # 2. T√≠nh T·ª∑ tr·ªçng theo T·ªïng T√†i s·∫£n
    tong_tai_san_row = df[df['Ch·ªâ ti√™u'].str.contains('T·ªîNG C·ªòNG T√ÄI S·∫¢N', case=False, na=False)]
    
    if tong_tai_san_row.empty:
        raise ValueError("Kh√¥ng t√¨m th·∫•y ch·ªâ ti√™u 'T·ªîNG C·ªòNG T√ÄI S·∫¢N'.")

    tong_tai_san_N_1 = tong_tai_san_row['NƒÉm tr∆∞·ªõc'].iloc[0]
    tong_tai_san_N = tong_tai_san_row['NƒÉm sau'].iloc[0]

    # X·ª≠ l√Ω l·ªói chia cho 0 th·ªß c√¥ng
    divisor_N_1 = tong_tai_san_N_1 if tong_tai_san_N_1 != 0 else 1e-9
    divisor_N = tong_tai_san_N if tong_tai_san_N != 0 else 1e-9

    df['T·ª∑ tr·ªçng NƒÉm tr∆∞·ªõc (%)'] = (df['NƒÉm tr∆∞·ªõc'] / divisor_N_1) * 100
    df['T·ª∑ tr·ªçng NƒÉm sau (%)'] = (df['NƒÉm sau'] / divisor_N) * 100
    
    return df

# --- H√†m g·ªçi API Gemini cho Ph√¢n t√≠ch Ban ƒë·∫ßu ---
def get_ai_analysis(data_for_ai, api_key):
    """G·ª≠i d·ªØ li·ªáu ph√¢n t√≠ch ƒë·∫øn Gemini API v√† nh·∫≠n nh·∫≠n x√©t."""
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(
            model_name='gemini-2.5-flash',
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                top_p=0.8,
                max_output_tokens=1000,
            ),
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }
        ) 

        # Prompt c·∫£i thi·ªán: Th√™m so s√°nh benchmark ng√†nh (gi·∫£ s·ª≠ ng√†nh s·∫£n xu·∫•t)
        prompt = f"""
        B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch t√†i ch√≠nh chuy√™n nghi·ªáp. D·ª±a tr√™n c√°c ch·ªâ s·ªë t√†i ch√≠nh sau c·ªßa doanh nghi·ªáp (ng√†nh s·∫£n xu·∫•t), h√£y ƒë∆∞a ra m·ªôt nh·∫≠n x√©t kh√°ch quan, ng·∫Øn g·ªçn (kho·∫£ng 3-4 ƒëo·∫°n) v·ªÅ t√¨nh h√¨nh t√†i ch√≠nh. 
        ƒê√°nh gi√° t·∫≠p trung v√†o t·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng, thay ƒë·ªïi c∆° c·∫•u t√†i s·∫£n v√† kh·∫£ nƒÉng thanh to√°n hi·ªán h√†nh. 
        So s√°nh v·ªõi benchmark ng√†nh: TƒÉng tr∆∞·ªüng t√†i s·∫£n > 10% l√† t·ªët; Thanh to√°n hi·ªán h√†nh > 1.5 l·∫ßn l√† an to√†n; T·ª∑ tr·ªçng t√†i s·∫£n ng·∫Øn h·∫°n > 30% l√† c√¢n b·∫±ng.
        
        D·ªØ li·ªáu th√¥ v√† ch·ªâ s·ªë:
        {data_for_ai}
        """

        response = model.generate_content(prompt)
        return response.text

    except GoogleAPIError as e:
        return f"L·ªói g·ªçi Gemini API: Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng. Chi ti·∫øt l·ªói: {e}"
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"

# --- H√†m g·ªçi API Gemini cho Chat ---
def get_ai_chat_response(messages, api_key, df_context=None):
    """G·ª≠i l·ªãch s·ª≠ chat ƒë·∫øn Gemini v√† nh·∫≠n ph·∫£n h·ªìi, v·ªõi ng·ªØ c·∫£nh d·ªØ li·ªáu n·∫øu c√≥."""
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(
            model_name='gemini-2.5-flash',
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                top_p=0.8,
                max_output_tokens=500,
            ),
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
            }
        )

        # X√¢y d·ª±ng prompt t·ª´ l·ªãch s·ª≠ chat
        chat_history = ""
        for msg in messages:
            role = "User" if msg["role"] == "user" else "Assistant"
            chat_history += f"{role}: {msg['content']}\n"

        # Th√™m ng·ªØ c·∫£nh d·ªØ li·ªáu n·∫øu c√≥
        if df_context is not None:
            context = f"""
            Ng·ªØ c·∫£nh d·ªØ li·ªáu t√†i ch√≠nh (B·∫£ng ph√¢n t√≠ch):
            {df_context}
            """
        else:
            context = ""

        prompt = f"""
        B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n v·ªÅ ph√¢n t√≠ch t√†i ch√≠nh. H√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch chuy√™n nghi·ªáp, ng·∫Øn g·ªçn v√† d·ª±a tr√™n d·ªØ li·ªáu n·∫øu c√≥. 
        N·∫øu c√¢u h·ªèi li√™n quan ƒë·∫øn d·ªØ li·ªáu t√†i ch√≠nh, h√£y tham chi·∫øu ƒë·∫øn ng·ªØ c·∫£nh sau:
        {context}
        
        L·ªãch s·ª≠ chat:
        {chat_history}
        
        C√¢u h·ªèi hi·ªán t·∫°i: {messages[-1]['content']}
        """

        response = model.generate_content(prompt)
        return response.text

    except GoogleAPIError as e:
        return f"L·ªói g·ªçi Gemini API: Vui l√≤ng ki·ªÉm tra Kh√≥a API ho·∫∑c gi·ªõi h·∫°n s·ª≠ d·ª•ng. Chi ti·∫øt l·ªói: {e}"
    except Exception as e:
        return f"ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh: {e}"

# --- Ch·ª©c nƒÉng 1: T·∫£i File ---
uploaded_file = st.file_uploader(
    "1. T·∫£i file Excel B√°o c√°o T√†i ch√≠nh (Ch·ªâ ti√™u | NƒÉm tr∆∞·ªõc | NƒÉm sau)",
    type=['xlsx', 'xls']
)

if uploaded_file is not None:
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        status_text.text("ƒêang ƒë·ªçc file...")
        progress_bar.progress(20)
        df_raw = pd.read_excel(uploaded_file)
        
        # Ti·ªÅn x·ª≠ l√Ω
        df_raw.columns = ['Ch·ªâ ti√™u', 'NƒÉm tr∆∞·ªõc', 'NƒÉm sau']
        progress_bar.progress(50)
        
        status_text.text("ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")
        df_processed = process_financial_data(df_raw.copy())
        st.session_state.df_processed = df_processed
        progress_bar.progress(80)
        
        # --- Ch·ª©c nƒÉng 4: T√≠nh Ch·ªâ s·ªë T√†i ch√≠nh (t√≠nh tr∆∞·ªõc ƒë·ªÉ d√πng cho data_for_ai) ---
        thanh_toan_hien_hanh_N = "N/A"
        thanh_toan_hien_hanh_N_1 = "N/A"
        try:
            # L·∫•y T√†i s·∫£n ng·∫Øn h·∫°n
            tsnh_row = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]
            if not tsnh_row.empty:
                tsnh_n = tsnh_row['NƒÉm sau'].iloc[0]
                tsnh_n_1 = tsnh_row['NƒÉm tr∆∞·ªõc'].iloc[0]

                # L·∫•y N·ª£ ng·∫Øn h·∫°n (fallback: n·∫øu kh√¥ng c√≥, d√πng t·ªïng n·ª£ ph·∫£i tr·∫£ n·∫øu c√≥, ho·∫∑c c·∫£nh b√°o)
                no_ngan_han_row = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('N·ª¢ NG·∫ÆN H·∫†N', case=False, na=False)]
                if no_ngan_han_row.empty:
                    # Fallback: T√¨m 'T·ªîNG N·ª¢ PH·∫¢I TR·∫¢' n·∫øu c√≥
                    no_phai_tra_row = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T·ªîNG N·ª¢ PH·∫¢I TR·∫¢', case=False, na=False)]
                    if not no_phai_tra_row.empty:
                        no_ngan_han_N = no_phai_tra_row['NƒÉm sau'].iloc[0]
                        no_ngan_han_N_1 = no_phai_tra_row['NƒÉm tr∆∞·ªõc'].iloc[0]
                        st.warning("S·ª≠ d·ª•ng 'T·ªîNG N·ª¢ PH·∫¢I TR·∫¢' l√†m fallback cho 'N·ª¢ NG·∫ÆN H·∫†N'.")
                    else:
                        raise IndexError("Kh√¥ng t√¨m th·∫•y 'N·ª¢ NG·∫ÆN H·∫†N' ho·∫∑c 'T·ªîNG N·ª¢ PH·∫¢I TR·∫¢'.")
                else:
                    no_ngan_han_N = no_ngan_han_row['NƒÉm sau'].iloc[0]
                    no_ngan_han_N_1 = no_ngan_han_row['NƒÉm tr∆∞·ªõc'].iloc[0]

                # X·ª≠ l√Ω chia 0
                divisor_N_1 = no_ngan_han_N_1 if no_ngan_han_N_1 != 0 else 1e-9
                divisor_N = no_ngan_han_N if no_ngan_han_N != 0 else 1e-9

                thanh_toan_hien_hanh_N = tsnh_n / divisor_N
                thanh_toan_hien_hanh_N_1 = tsnh_n_1 / divisor_N_1
                
                st.session_state.thanh_toan_hien_hanh_N_1 = f"{thanh_toan_hien_hanh_N_1:.2f}"
                st.session_state.thanh_toan_hien_hanh_N = f"{thanh_toan_hien_hanh_N:.2f}"
            else:
                raise IndexError("Kh√¥ng t√¨m th·∫•y 'T√ÄI S·∫¢N NG·∫ÆN H·∫†N'.")
        except IndexError:
            st.warning("Thi·∫øu ch·ªâ ti√™u c·∫ßn thi·∫øt ƒë·ªÉ t√≠nh ch·ªâ s·ªë thanh to√°n. Vui l√≤ng ki·ªÉm tra file Excel.")
        
        # Chu·∫©n b·ªã data_for_ai cho ph√¢n t√≠ch ban ƒë·∫ßu v√† chat
        tsnh_row = df_processed[df_processed['Ch·ªâ ti√™u'].str.contains('T√ÄI S·∫¢N NG·∫ÆN H·∫†N', case=False, na=False)]
        tang_truong_tsnh = tsnh_row['T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)'].iloc[0] if not tsnh_row.empty else "N/A"
        
        st.session_state.data_for_ai = pd.DataFrame({
            'Ch·ªâ ti√™u': [
                'To√†n b·ªô B·∫£ng ph√¢n t√≠ch (d·ªØ li·ªáu th√¥)', 
                'TƒÉng tr∆∞·ªüng T√†i s·∫£n ng·∫Øn h·∫°n (%)', 
                'Thanh to√°n hi·ªán h√†nh (N-1)', 
                'Thanh to√°n hi·ªán h√†nh (N)'
            ],
            'Gi√° tr·ªã': [
                df_processed.to_markdown(index=False),
                f"{tang_truong_tsnh:.2f}%", 
                st.session_state.thanh_toan_hien_hanh_N_1, 
                st.session_state.thanh_toan_hien_hanh_N
            ]
        }).to_markdown(index=False)
        
        progress_bar.progress(100)
        status_text.text("X·ª≠ l√Ω ho√†n t·∫•t!")
        st.success("File ƒë√£ ƒë∆∞·ª£c t·∫£i v√† x·ª≠ l√Ω th√†nh c√¥ng.")

        # --- Ch·ª©c nƒÉng 2 & 3: Hi·ªÉn th·ªã K·∫øt qu·∫£ ---
        st.subheader("2. T·ªëc ƒë·ªô TƒÉng tr∆∞·ªüng & 3. T·ª∑ tr·ªçng C∆° c·∫•u T√†i s·∫£n")
        st.dataframe(df_processed.style.format({
            'NƒÉm tr∆∞·ªõc': '{:,.0f}',
            'NƒÉm sau': '{:,.0f}',
            'T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng (%)': '{:.2f}%',
            'T·ª∑ tr·ªçng NƒÉm tr∆∞·ªõc (%)': '{:.2f}%',
            'T·ª∑ tr·ªçng NƒÉm sau (%)': '{:.2f}%'
        }), use_container_width=True)
        
        # N√∫t Export
        col_export1, col_export2 = st.columns(2)
        with col_export1:
            if st.button("üì• T·∫£i k·∫øt qu·∫£ Excel"):
                output = io.BytesIO()
                df_processed.to_excel(output, index=False)
                output.seek(0)
                st.download_button(
                    label="T·∫£i file",
                    data=output.getvalue(),
                    file_name="ket_qua_phan_tich.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        
        # --- Ch·ª©c nƒÉng 4: T√≠nh Ch·ªâ s·ªë T√†i ch√≠nh (hi·ªÉn th·ªã) ---
        st.subheader("4. C√°c Ch·ªâ s·ªë T√†i ch√≠nh C∆° b·∫£n")
        
        if st.session_state.thanh_toan_hien_hanh_N != "N/A":
            col1, col2 = st.columns(2)
            with col1:
                st.metric(
                    label="Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh (NƒÉm tr∆∞·ªõc)",
                    value=f"{float(st.session_state.thanh_toan_hien_hanh_N_1):.2f} l·∫ßn"
                )
            with col2:
                st.metric(
                    label="Ch·ªâ s·ªë Thanh to√°n Hi·ªán h√†nh (NƒÉm sau)",
                    value=f"{float(st.session_state.thanh_toan_hien_hanh_N):.2f} l·∫ßn",
                    delta=f"{float(st.session_state.thanh_toan_hien_hanh_N) - float(st.session_state.thanh_toan_hien_hanh_N_1):.2f}"
                )
        else:
            st.warning("Kh√¥ng th·ªÉ t√≠nh ch·ªâ s·ªë thanh to√°n do thi·∫øu d·ªØ li·ªáu.")
        
        # --- Ch·ª©c nƒÉng 5: Nh·∫≠n x√©t AI Ban ƒë·∫ßu ---
        st.subheader("5. Nh·∫≠n x√©t T√¨nh h√¨nh T√†i ch√≠nh (AI)")
        
        if st.button("Y√™u c·∫ßu AI Ph√¢n t√≠ch Ban ƒë·∫ßu"):
            api_key = st.secrets.get("GEMINI_API_KEY") 
            
            if api_key:
                with st.spinner('ƒêang g·ª≠i d·ªØ li·ªáu v√† ch·ªù Gemini ph√¢n t√≠ch...'):
                    ai_result = get_ai_analysis(st.session_state.data_for_ai, api_key)
                    st.markdown("**K·∫øt qu·∫£ Ph√¢n t√≠ch t·ª´ Gemini AI:**")
                    st.info(ai_result)
            else:
                st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API. Vui l√≤ng c·∫•u h√¨nh Kh√≥a 'GEMINI_API_KEY' trong Streamlit Secrets.")

        # --- Ch·ª©c nƒÉng 6: Khung Chat v·ªõi Gemini ---
        st.subheader("6. Chat v·ªõi AI: H·ªèi th√™m v·ªÅ D·ªØ li·ªáu T√†i ch√≠nh")
        st.info("üí° B·∫°n c√≥ th·ªÉ h·ªèi th√™m: 'Ph√¢n t√≠ch r·ªßi ro n·ª£?', 'So s√°nh v·ªõi nƒÉm tr∆∞·ªõc?', ho·∫∑c b·∫•t k·ª≥ c√¢u h·ªèi n√†o li√™n quan ƒë·∫øn d·ªØ li·ªáu.")
        
        # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # Chat input
        if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n..."):
            # Th√™m user message
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # G·ªçi AI
            api_key = st.secrets.get("GEMINI_API_KEY")
            if api_key:
                with st.chat_message("assistant"):
                    with st.spinner("ƒêang suy nghƒ©..."):
                        response = get_ai_chat_response(st.session_state.messages, api_key, st.session_state.data_for_ai)
                        st.markdown(response)
                        st.session_state.messages.append({"role": "assistant", "content": response})
            else:
                st.error("L·ªói: Kh√¥ng t√¨m th·∫•y Kh√≥a API cho chat.")

    except ValueError as ve:
        st.error(f"L·ªói c·∫•u tr√∫c d·ªØ li·ªáu: {ve}")
    except Exception as e:
        st.error(f"C√≥ l·ªói x·∫£y ra khi ƒë·ªçc ho·∫∑c x·ª≠ l√Ω file: {e}. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file.")

else:
    st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")
